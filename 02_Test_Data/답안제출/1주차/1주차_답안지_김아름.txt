1,2-(1) O
1,2-(2) 특성 공학
1,2-(3) 옵티마이저
1,2-(4) x의 행 크기와 y 열 크기가 같아야 함
1,2-(5) 손실 함수의 최저점으로 더 빠르게 수렴하기 위해
3,4-(1) 네트워크가 손실 함수를 최소화하기 위해 잘못된 모델이 만들어 질 수 있어서
3,4-(2) 1
3,4-(3) 46
3,4-(4) 레이블 (경험적인 알고리즘을 사용하여 입력 데이터로부터 생성)
3,4-(5) x
5,6-(1) 이미지의 특정 부분에서 어떤 패턴을 학습했다면 다른 부분에서도 패턴 인식이 가능함
5,6-(2) 상위 층이 구체적인 특성을 다루기 때문에
5,6-(3) 0, 30 / 배치에 있는 모든 시퀀스는 길이가 같아야 하므로 (하나의 텐서에 담아야 하기 때문에) 작은 길이의 시퀀스는 0으로 패딩되고 길이가 더 긴 시퀀스는 잘리게 된다.
5,6-(4) 과대 적합이 발생했을 때
5,6-(5) 긴 시퀀스를 처리하는데 적합하지 않으며 데이터의 타임스텝이 커질수록 학습 능력이 감소한다. 이는 그래디언트 소실 문제를 발생시킨다.
7,8-(1) 자연어 질문과 그에 대한 답변이 담긴 2개의 입력을 받고 벡터로 연결한 뒤 소프트맥스 함수를 통해 미리 정의한 어휘 사전에서 한 단어로 된 답을 출력한다
7,8-(2) 검증 손실이 더 이상 향상되지 않을 때 훈련을 중지한다 / 훈련하는 동안 하이퍼파라미터 값을 동적으로 조정한다
7,8-(3)탐욕적 샘플링은 항상 가장 높은 확률을 가진 글자를 선택하고, 반복적이며 예상 가능한 문자열을 만들어 논리적인 언어처럼 보이지 않는다. 확률적 샘플링은 샘플링하는 과정에 무작위성을 주입하며
모델의 소프트맥스 출력에 사용하기 좋다. 하지만 샘플링 과정에서 무작위성의 양을 조절할 방법이 없다. 소프트맥스 온도는 샘플링 과정에서 확률의 양을 조절하기 위한 파라미터로, 샘플링에 사용되는
확률 분포의 엔트로피를 나타낸다. 또한 얼마나 놀라운 / 예상되는 글자를 선택할지 결정한다.
7,8-(4) 연속적인 스케일에 걸쳐 경사 상승법을 실행한다. resize_img 함수를 사용한다.
7,8-(5) 웃는 남자 이미지
7,8-(6) 생성자가 랜덤 벡터를 입력으로 받은 후 이를 합성한 이미지로 디코딩한 결과를 받아 판별자가 실제 이미지라고 판단되면 1, 가짜라면 0을 출력하며 훈련된다.
생성자는 이런 판별자의 결과를 보고 손실을 최소화 시키는 방향으로 학습한다.
1,2-(1) O
1,2-(2) 전처리
1,2-(3) 컴파일
1,2-(4) x의 행 벡터와 y의 열 벡터가 같은 크기여야 한다.
1,2-(5) 모멘텀은 SGD로 최적화 되었다면 전역최솟값에 향하지못하고 지역 최솟값에 갇히는걸 해결해주기때문이다
3,4-(1) 네트워크가 손실을 최소화하기 위해 편법을 사용할 수 있기 때문이다.
3,4-(2) 3
3,4-(3) 5
3,4-(4) 레이블
3,4-(5) X
5,6-(1) 한쪽에서 어떤 패턴을 학습했다면 다른 곳에서도 이 패턴을 인식할 수 있는 것
5,6-(2) 분류기가 미리 훈련되지 않으면 훈련되는 동안 너무 큰 오차 신호가 네트워크에 전파되기 때문
5,6-(3) 사용할 텍스트의 길이가 30이기때문에 둘다 30으로 맞춰진다.
5,6-(4) 과대적합을 방지한 상황
5,6-(5) 기억의 장기 의존성이 문제가 되어서 텍스트같은 긴 시퀀스를 처리하는데에 적합하지 못하다.
7,8-(1) 텍스트와 질문을 벡터로 인코딩하여 독립된 입력 2개를 정의하고 이 벡터를 연결하여 소프트맥스 분류기를 추가한다.
7,8-(2) 1-검증 손실이 향상되지 않을 경우, 훈련을 중지시켜준다.  2-에포크에 따라 학습률을 조정한다.
7,8-(3) 탐욕적 샘플링은 항상 가장 높은 확률을 가진 글자를 선택하고, 확률적 샘플링은 다음 글자의 확률 분포에서 샘플링 하는 과정에 무작위성을 주입한다는 특징을 가졌다. 
확률적 샘플링 과정에서 무작위성의 양을 조절할 방법이 없는데, 이때 소프트맥스 온도가 조절할 수 있게 해준다.
7,8-(4) 딥드림
7,8-(5) 같은 얼굴이 웃고있는 이미지
7,8-(6) 생성자는 판별자 네트워크를 속이도록, 판별자는 생성된 이미지가 실제인지 판별하는 기준을 설정하면서 생성자의 능력향상에 적응해 나가도록 한다.
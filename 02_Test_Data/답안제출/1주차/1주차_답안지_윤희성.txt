1,2-(1) O
1,2-(2) 데이터 전처리
1,2-(3) 옵티마이저
1,2-(4) x.shape[1] == y.shape[0]일 때 가능
1,2-(5) 모멘텀은 SGD의 수렴 속도 문제와 지역 최솟값 문제를 해결하기 때문
3,4-(1) 목적 함수를 현명하게 선택하지 않으면 원하지 않는 부수 효과가 발생할 수 있기 때문
3,4-(2) 3
3,4-(3) 5
3,4-(4) 수정하지 않은 원본 입력
3,4-(5) X
5,6-(1) 이미지의 패턴을 학습했다면 다른 위치에서도 인식할 수 있는 성질
5,6-(2) 상위 층은 구체적인 특성을 나타내기 때문에
5,6-(3) 둘 다 30, 첫 번째 것은 제로패딩돼 30으로 채워지고 두 번째 꺼는 30까지만 사용됨
5,6-(4) 충분히 과대적합 후 드롭 아웃 기법을 사용시 loss값이 낮아질 수 있음
5,6-(5) 심플RNN을 사용시 그래디언트 소실 문제가 발생할 수 있다. 이는 타임스텝이 길어질 시 긴 시간에 걸친 의존성은 학습할 수 없게되는 문제이다.
7,8-(1) 참고 텍스트와 질문을 LSTM으로 학습 후 결합해 출력한다.
7,8-(2) 1, 설정한 회수만큼 손실이 향상되지 않을 시 훈련을 중지함 2, 에포크에 따라서 학습률을 조정함
7,8-(3) 
7,8-(4) 옥타브
7,8-(5) 웃는 남자
7,8-(6) 
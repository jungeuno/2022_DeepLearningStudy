1,2-(1) O
1,2-(2) 데이터 전처리 과정
1,2-(3) 옵티마이저
1,2-(4) 왼쪽 행렬의 열 개수와 오른쪽 행렬의 행 개수가 같아야 합니다.
1,2-(5) 경사하강법의 문제점을 보완한다. 경사하강법을 사용했을 경우 최소값을 잘 못 정하여 계산이 끝났을 상황이 발생할 수 있는데, 모멘텀을 사용하면 관성의 힘을 빌리며 값이 조절되며 올바른 값을 얻을 수 있다.
3,4-(1) 목적 함수가 주어진 문제의 성공과 전혀 관련이 없다면 원하지 않는 일을 수행하는 모델이 만들어질 것이기 때문에 적절한 목적 함수를 사용해야합니다.
3,4-(2) 3번
3,4-(3) 5
3,4-(4) 다량의 Label이 없는 데이터들의 관계를 통해 Label을 자동으로 생성한다.
3,4-(5) X
5,6-(1) 컨브넷이 이미지의 임의의 위치에서 패턴을 학습했다면 다른 위치에서도 이 패턴을 인식할 수 있는 성질입니다.
5,6-(2) 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 이코딩하는 반면, 상위층은 좀 더 특화된 특성을 인코딩하기 때문에, 새로운 문제에 재활용하도록 수정이 필요한 것은 구체적인 특성이므로 상위 층을 미세 조정 하는 것이 유리합니다.
5,6-(3) 텍스트 1은 30보다 길이가 짧으므로 나머지 부분은 0으로 패딩되고, 텍스트 2는 30보다 크므로 나머지 부분은 잘립니다.
5,6-(4) 모델 설계시 과대적합이 발생했기 때문에 드롭아웃 기법을 사용함으로써 loss 값이 더 낮아진다.
5,6-(5)  Simple RNN의 타임스텝이 길어질수록 과거의 입력에 지나치게 의존하기 때문에 현재 출력에 대한 원하는 결과를 얻을 수 없는 단점을 가지고 있다. (그래디언트 소실 문제)
7,8-(1) 입력 2개를 받은 후 미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력
7,8-(2) EarlyStopping : 모델이 더 이상 학습을 못할 경우 학습 도중 미리 학습을 종료시키는 콜백함수
LearningRateScheduler : epoch에 따라 학습률을 조정하는 콜백함수
7,8-(3) 탐욕적 샘플링 : 가장 높은 확률을 가진 글자를 선택하는 방법
확률적 샘플링 : 소프트맥스 결과값에서 가중치에 따라 랜덤으로 선택하는 방법
소프트맥스 온도 : 샘플링에 사용되는 확률 분포의 엔트로피를 나타내는 역할
7,8-(4) 딥드림과정 - 옥타브
7,8-(5) 남자가 웃고있는 사진
7,8-(6) 생성자는 랜덤한 숫자로 구성된 벡터를 입력으로 받아 최대한 진짜 같이 보이는 가짜 샘플을 출력하고, 판별자는 실제 샘플 또는 가짜 샘플을 입력으로 받아 입력 샘플이 진짜일 예측 확률을 출력합니다.

1,2-(1) 0
1,2-(2) 
1,2-(3) 옵티마이저
1,2-(4) x의 행 벡터와 y의 열 벡터가 같은 크기여야 하므로 자동으로 x의 너비는 y의 높이와 동일해야 한다
1,2-(5) 모멘텀을 사용하면 가중치 값이 바로 바뀌지 않고 어느 정도 일정한 방향을 유지하면서 움직이게 되며, 
         같은 방향으로 더 많이 변화시켜 학습속도를 향상시켜준다.
3,4-(1) 모든 신경망은 손실 함수를 최소화하기 때문에, 네트워크가 손실을 최소화 할 수 있기 때문이다.
3,4-(2) 3
3,4-(3) 5
3,4-(4) 
3,4-(5) X
5,6-(1) 이미지의 어떤 패턴을 학습했다는 가정 하에, 다른 위치에서도 패턴 인식이 가능하다.
5,6-(2) 합성곱 기반 층에 있는 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 인코딩 하지만,
          상위층은 좀 더 특화된 특성을 인코딩 하기 때문에, 새로운 문제에 재활용 하도록 수정이 필요한 것은
          구체적인 특성이기 때문에 상위층 미세조정이 좀 더 효율적이다.
5,6-(3) 텍스트 1에서 여유분은 제로패딩 되고 텍스트 2는 30이 넘는 범위부터 삭제된다. 
5,6-(4) 동일한 드롭아웃 마스크를 모든 타임스텝에 적용할 경우
5,6-(5) 그래디언트 소실 문제 - 학습 시간이 길어지면 학습 내용 소실 위험성이 커짐
7,8-(1) 텍스트와 질문을 벡터로 인코딩하여 독립된 입력 2개를 지정하고, 벡터를 연결한 후 소프트맥스 분류기를 추가한다.
7,8-(2) 1. 검증 손실이 향상되지 않을 경우, 훈련을 중지시킨다.
         2. 에포크에 따라 학습률을 조정한다.
7,8-(3) 탐욕적 샘플링이란, 항상 가장 높은 확률을 가진 글자를 선택하는 것이고, 
         확률적 샘플링이란, 다음 글자의 확률 분포에서 샘플링하는 과정에서 무작위성을 주입하는 방법이다. 
         샘플링 과정에서 확률의 양을 조절하기 위해 사용하는 파라미터는 소프트맥스 온도이다.
7,8-(4) 옥타브 (딥드림과정)
7,8-(5) 해당 남성이 웃고있는 이미지
7,8-(6) 생성자는 랜덤벡터를 입력으로 받아 실제와 구분할 수 없는 이미지를 만들어 판별자가 두 이미지를 동일하게 보도록 하고, 
         판별자는 생성된 이미지가 실제인지 판별하는 기준을 설정하면서 생성자의 능력 향상에 적응해간다.
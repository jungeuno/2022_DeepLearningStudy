1,2-(1)
O
1,2-(2)
특성공학
1,2-(3)
옵티마이저
1,2-(4)
서로 원소개수가 같은 벡터끼리 가능하다.
1,2-(5)
지역최솟값이 아닌 전역 최솟값으로 도달하기 위해서이다.
3,4-(1)
네트워크가 손실을 최소화 하기위해 편법을 사용할 수 있기 때문이다.
3,4-(2)
3
3,4-(3)
5
3,4-(4)
예측
3,4-(5)
x
5,6-(1)
적은 수의 훈련 샘플을 사용해서 일반화 능력을 가진 표현을 학습할 수 있는 것
5,6-(2)
하위층은 일반적이고 재사용 가능한 특성들을 인코딩하고 상위층은 좀 더 특화된 특성을 인코딩하기때문
5,6-(3)
텍스트 길이를 30으로 만든다.
5,6-(4)
과대적합이 나타나서
5,6-(5)
긴 시퀀스를 처리하는데 적합하지 않다. 순서대로 입력하기 때문
7,8-(1)
참고 텍스트->임베딩->LSTM->Concatenate->Dense->응답
	질문 ->임베딩->LSTM->
7,8-(2)
1.검증 손실이 향상되지 않을 경우, 훈련을 중지시킨다.
2.에포크에 따라 학습률을 조정한다.
7,8-(3)
탐욕적 샘플링은 항상 높은 확률을 가진 글자를 선택한다
확률적 샘플링은 무작위성을 주입하는 방법이다.
소프트맥스 온도는 샘플링 과정에서 확률의 양을 조절한다.
7,8-(4)
옥타브
7,8-(5)
웃는 남자의 얼굴
7,8-(6)
생성자: 랜덤벡터를 입력으로 받아 합성된 이미지를 디코딩
판별자: 이미지를 입력으로 받아 훈련세트에서 온 이미지인지, 생성자가 네트워크가 만든 이미지인지 판별
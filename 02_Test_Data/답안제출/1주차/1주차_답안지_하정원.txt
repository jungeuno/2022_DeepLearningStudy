1,2-(1) O
1,2-(2) 특성 공학
1,2-(3) 옵티마이저
1,2-(4)  x의 행 벡터와 y의 열 벡터가 같은 크기여야 하므로 자동으로 x의 너비는 y의 높이와 동일해야 한다.
1,2-(5) SGD에 있는 문제점인 수렴 속도와 지역 최솟값을 해결해주기 때문이다.
3,4-(1) 네트워트가 손실을 최소화하기 위해 편법을 사용할 수 있기 때문이다.
3,4-(2) 1번
3,4-(3) 5
3,4-(4) 레이블
3,4-(5) O
5,6-(1) 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면 다른 곳에서도 이 패턴을 인식할 수 있다.
5,6-(2) 하위 층들은 좀 더 일반적이고 재사용 가능한 특성들을 인코딩한다. 반면에 상위 층은 좀 더 특화된 특성들을 인코딩하기 때문이다.
5,6-(3) 길이가 27인 텍스트의 경우 나머지 3은 0으로 패딩이 되고 길이가 35인 텍스트의 경우 30으로 시퀀스가 잘린다.
5,6-(4) 타임스텝 동안 일정한 드롭아웃 마스크와 순환 드롭아웃 마스크를 사용해야한다. 
5,6-(5) SimpleRNN은 이론적으로 이전의 정보들까지 유지할 수 있는데 실제로는 긴 시간에 걸친 의존성은 학습할 수 없는 것이 문제점이다.
레이어가 많은 일반 네트워크에서 나타나는 것과 비슷한 현상인 그래디언트 소실 문제 때문이다.
7,8-(1) 질문-응답 모델은 2개의 입력을 가지고 하나는 자연어 질문이고 또 하나는 답변에 대한 필요한 정보가 담겨있는 텍스트이다. 그러면 모델은 답을 출력해야 한다.
미리 정의한 어휘 사전에서 소프트맥스 함수를 통해 한 단어로 된 답을 출력한다.
7,8-(2)
keras.callbacks.EarlyStopping - 가장 좋은 모델을 저장하고 검증 손실을 향상하지 않고 훈련을 중지한다.
keras.callbacks.LearningRateScheduler - 에포크에 따라 학습률을 조정하는 기능을 한다.
7,8-(3)
탐욕적 샘플링 - 반복적이고 예상 가능한 문자열을 만든다.
확률적 샘플링 - 다음 글자의 확률 분포에서 샘플링하는 과정에 무작위성을 주입한다.
소프트맥스 온도 - 샘플링 과정에서 확률의 양을 조절하기 위한 파라미터
7,8-(4) 옥타브
7,8-(5) 웃고 있는 남자의 이미지
7,8-(6) 생성자는 생성된 데이터로 판별자가 실제 데이터로 착각하도록 학습하고 판별자는 실제 데이터와 생성자가 생성한 거짓 데이터를 구분하도록 학습한다.
1,2-(1) o
1,2-(2) 특성공학
1,2-(3) 옵티마이저
1,2-(4) x의 행의 크기와 y의 열의 크기가 같을 때 성립된다
1,2-(5) SGD 최적화 과정에서 지역 최소값에 빠지는 문제와 수렴 속도 문제를 모두 해결할 수 있기 때문 
3,4-(1) 네트워크가 손실을 최소화하기 위해 편법을 사용할 수 있기 때문
3,4-(2) 3번
3,4-(3) 5
3,4-(4) 레이어를 자동으로 생성
3,4-(5) x
5,6-(1) 이미지의 오른쪽 아래 모서리에서 어떤 패턴을 학습했다면
         다른 곳에서도 이 패턴을 인식할 수 있음 
5,6-(2) 상위 층이 구체적인 특성을 다루기 때문에 상위 층을 미세 조정하는 것이 유리하다
5,6-(3) 30, 
5,6-(4) 드롭아웃이 잘 진행되어 과대 적합이 되지 않은 것 
5,6-(5) 장기의존성문제, 입력 데이터가 길어질수록 학습 능력이 떨어진다
7,8-(1) 질문과 텍스트를 입력받아 Embedding layer와 LSTM을 순차적으로 지나고
          두 LSTM을 Concatenate로 합쳐 응답을 출력해낸다.
7,8-(2)  1) 과대 적합이 일어나기 전에 훈련을 일찍 멈추어주는 함수
           2) 에포크에 따라 학습률을 조정해주는 함수 
7,8-(3) 탐욕적 샘플링은 반복적이고 예상이 가능한 문자열을 만들고 
          확률적 샘플링은 소프트 맥스의 결과값의 가중치에 따라서 랜덤으로 선택한다
         
7,8-(4) 옥타브
7,8-(5) z+s는 웃고있는 남자의 얼굴 이미지 
7,8-(6) 생성자는 생성자를 받아서 실제 데이터와 비슷한 데이터를 만들어내도록 학습하고,
         구분자는 실제 데이터와 생성자가 생성한 가짜 데이터를 구별하도록 학습한다.